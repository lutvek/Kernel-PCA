{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.util import random_noise\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import kpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pca(X):\n",
    "    n = X.shape[0]\n",
    "    Xcentered = X - np.mean(X,0)\n",
    "    C = 1.0/n*Xcentered.T.dot(Xcentered)\n",
    "    D, V = np.linalg.eigh(C)\n",
    "    return (D, V)\n",
    "\n",
    "def gaussianKernel(x, y, c):\n",
    "\t''' Returns K(x,y) where K denotes gaussian kernel '''\n",
    "\treturn math.exp(-(np.linalg.norm(x-y)**2) / c)\n",
    "\n",
    "def createK(data, kernelFunction, c):\n",
    "\t''' Returns K matrix containing inner products of the data using the kernel function \n",
    "\tso that K_ij := (phi(x_i)*phi(x_j)) '''\n",
    "\tl = len(data)\n",
    "\tK = np.zeros((l,l))\n",
    "\tfor col in range(l):\n",
    "\t\tfor row in range(l):\n",
    "\t\t\tK[row][col] = kernelFunction(data[row],data[col], c)\n",
    "\treturn K\n",
    "\n",
    "def calcBetaK(alphaK, kernelFunction, data, x, c):\n",
    "\t''' Returns the projection of x onto the eigenvector V_k '''\n",
    "\tBetaK = 0\n",
    "\tfor i,xi in enumerate(data):\n",
    "\t\tBetaK += alphaK[i]*kernelFunction(xi,x,c)\n",
    "\treturn BetaK\t\n",
    "\t\n",
    "def centerK(K):\n",
    "\t''' Returns centered K matrix, see K. Murphy 14.43 '''\n",
    "\tl = len(K)\n",
    "\tl_ones = np.ones((l, l), dtype=int) / l\n",
    "\tKcentered = K - np.dot(l_ones,K)-np.dot(K,l_ones)+np.dot(l_ones,np.dot(K,l_ones))\t\n",
    "\treturn Kcentered\n",
    "\n",
    "def normAlpha(alpha, lambdas):\n",
    "\t''' Returns new alpha corresponding to normalized eigen vectors,\n",
    "\tso that lambda_k(a^k * a^k) = 1 '''\n",
    "\tfor i,a in enumerate(alpha):\n",
    "\t\ta /= np.sqrt(lambdas[i])\n",
    "\treturn alpha\n",
    "\n",
    "def calcZold(alpha, data, x, kernelFunction, c,z0):\n",
    "\t''' Equation (10), returns pre-image z for single input datapoint x '''\n",
    "\tz = z0\n",
    "\titers=0\n",
    "\twhile iters <5:\n",
    "\t\tnumerator = 0\n",
    "\t\tdenom = 0\n",
    "\t\tfor i, xi in enumerate(data):\n",
    "\t\t\tgammaI = calcGammaI(alpha, i, data, x, kernelFunction, c) * kernelFunction(z,xi,c)\n",
    "\t\t\tnumerator += gammaI * xi\n",
    "\t\t\tdenom += gammaI\n",
    "\t\tz = numerator/denom\n",
    "\t\titers +=1\n",
    "\treturn z\n",
    "\n",
    "def calcZ(alpha, data, x, kernelFunction, c,z0):\n",
    "\t''' Equation (10), returns pre-image z for single input datapoint x '''\n",
    "\tz = z0\n",
    "\titers=0\n",
    "\tmaxIters = 1000\n",
    "\t# calculate beta (does not change with each iteration)\n",
    "\tbeta = [calcBetaK(aK, kernelFunction, data, x, c) for aK in alpha]\n",
    "\n",
    "\twhile iters < maxIters: # iterate until convergence\n",
    "\t\tnumerator = 0\n",
    "\t\tdenom = 0\n",
    "\t\tfor i, xi in enumerate(data):\n",
    "\t\t\t#gammaI = calcGammaI(alpha, i, data, x, kernelFunction, c) * kernelFunction(z,xi,c)\n",
    "\t\t\tgammaI = calcGammaIOpt(alpha, i, beta) * kernelFunction(z,xi,c)\n",
    "\t\t\tnumerator += gammaI * xi\n",
    "\t\t\tdenom += gammaI\n",
    "\t\tif denom > 10**-12: #handling numerical instability\n",
    "\t\t\tnewZ = numerator/denom\n",
    "\t\t\tif np.linalg.norm(z - newZ) < 10**-8:\n",
    "\t\t\t\tz = newZ\n",
    "\t\t\t\tbreak\n",
    "\t\t\tz = newZ\n",
    "\t\t\titers += 1\n",
    "\t\telse:\n",
    "\t\t\titers =0\n",
    "\t\t\tz=z0 + np.random.multivariate_normal(np.zeros(z0.size),np.identity(z0.size))\n",
    "\t\t\tnumerator = 0\n",
    "\t\t\tdenom = 0\n",
    "\n",
    "\treturn z\n",
    "\n",
    "def calcGammaI(alpha, i, data, x, kernelFunction, c):\n",
    "\t''' returns gamma_i = sum_{k=1}^n Beta_k * alpha_i^k '''\n",
    "\tgammaI = 0\n",
    "\talphaI = alpha.T[i]\n",
    "\tfor k, alphaKI in enumerate(alphaI):\n",
    "\t\tgammaI += calcBetaK(alpha[k], kernelFunction, data, x, c) * alphaKI\n",
    "\treturn gammaI\n",
    "\n",
    "def calcGammaIOpt(alpha, i, beta):\n",
    "\t''' returns gamma_i = sum_{k=1}^n beta_k * alpha_i^k '''\n",
    "\tgammaI = 0\n",
    "\talphaI = alpha.T[i]\n",
    "\tfor k, alphaKI in enumerate(alphaI):\n",
    "\t\tgammaI += beta[k] * alphaKI\n",
    "\treturn gammaI\n",
    "\n",
    "def kernelPCADeNoise(kernelFunction, c, components, dataTrain, dataTest):\n",
    "\tData = dataTrain\n",
    "\n",
    "\tl = len(Data)\n",
    "\n",
    "\t# build K\n",
    "\tK = createK(Data, kernelFunction, c)\n",
    "\n",
    "\t# center K\n",
    "\tK = centerK(K)\n",
    "\n",
    "\t# find eigen vectors\n",
    "\tlLambda, alpha = np.linalg.eigh(K) # (3)\n",
    "\tlambdas = lLambda/l # /l with the notation from the paper (but not murphys) \n",
    "\t# drop negative and 0 egienvalues and their vectors\n",
    "\tfor i,l in enumerate(lambdas):\n",
    "\t\tif l > 10**(-8):\n",
    "\t\t\tlambdas = lambdas[i:]\n",
    "\t\t\talpha = alpha[i:]\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# use only the 4 larges eigen values with corresponding vectors\n",
    "\tlambdas=lambdas[-components:]\n",
    "\talpha=alpha[-components:]\n",
    "\n",
    "\t# normalize alpha\n",
    "\talpha = normAlpha(alpha, lambdas)\n",
    "\n",
    "\tZ =[]\n",
    "\tfor i in range(len(dataTest)):\n",
    "\t\tZ.append(calcZ(alpha, Data, dataTest[i],kernelFunction,c,dataTest[i]))\n",
    "\n",
    "\tZ=np.array(Z)\n",
    "\treturn Z\n",
    "\n",
    "def add_white_noise(X):\n",
    "    # add additive noise\n",
    "    return X + np.random.normal(size=X.shape)/2\n",
    "\n",
    "def add_sp_noise(X):\n",
    "    # add salt and pepper noise\n",
    "    Y = copy.deepcopy(X)\n",
    "    Y[np.random.choice(range(256),size=40,replace=False)]=1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read usps dataset\n",
    "usps = fetch_mldata('usps')\n",
    "# size of the sample\n",
    "n = 300\n",
    "# find size amount of samples of number digit\n",
    "\n",
    "#idx = np.random.choice(usps.data.shape[0],size=n, replace=False)\n",
    "\n",
    "# randomly take n samples of every digit\n",
    "idx = []\n",
    "for digit in range(10):\n",
    "    idx = idx + list(np.random.choice(np.where((usps.target-1) == digit)[0], size=n, replace=False))\n",
    "\n",
    "Xtrain = usps.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform pca\n",
    "D, V = pca(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Figure 2: plot of the eigenvectors of C (PCA) \n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(8):  \n",
    "    fig.add_subplot(1,8,i+1)\n",
    "    plt.imshow(V.T[-(2**i)].reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "    plt.axis('off') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Figure 3: plot the reconstructions using PCA\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "X = Xtrain[np.random.randint(Xtrain.shape[0])]\n",
    "\n",
    "for i in range(20):  \n",
    "    fig.add_subplot(1,21,i+1)\n",
    "    Xapprox = X.dot(V[:,-i-1:]).dot(V[:,-i-1:].T)\n",
    "    plt.imshow(Xapprox.reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "    plt.axis('off') \n",
    "    error = np.linalg.norm(X-Xapprox)\n",
    "    plt.title(round(error,2))\n",
    "\n",
    "fig.add_subplot(1,21,21)\n",
    "plt.imshow(X.reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "plt.axis('off') \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Figure 4: Denoising using PCA\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(10):\n",
    "    # plot 1 sample from every digit class\n",
    "    Xsample = Xtrain[i*n]\n",
    "    \n",
    "    fig.add_subplot(7,20,i+1)    \n",
    "    plt.imshow(Xsample.reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "    plt.axis('off') \n",
    "    \n",
    "    fig.add_subplot(7,20,10+i+1)    \n",
    "    plt.imshow(Xsample.reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "    plt.axis('off') \n",
    "    \n",
    "    # plot noisy version of it\n",
    "    Xwn = add_white_noise(Xsample)\n",
    "    Xsp = add_sp_noise(Xsample)\n",
    "    \n",
    "    fig.add_subplot(7,20,20+i+1)    \n",
    "    plt.imshow(Xwn.reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "    plt.axis('off') \n",
    "    \n",
    "    fig.add_subplot(7,20,30+i+1)    \n",
    "    plt.imshow(Xsp.reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "    plt.axis('off') \n",
    "    \n",
    "    for j in range(5):\n",
    "        fig.add_subplot(7,20,40+j*20+i+1)\n",
    "        Xapprox = Xwn.dot(V[:,-4**j:]).dot(V[:,-4**j:].T)\n",
    "        plt.imshow(Xapprox.reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "        plt.axis('off') \n",
    "        \n",
    "        fig.add_subplot(7,20,50+j*20+i+1)\n",
    "        Xapprox = Xsp.dot(V[:,-4**j:]).dot(V[:,-4**j:].T)\n",
    "        plt.imshow(Xapprox.reshape((16,16)), cmap=plt.cm.Greys, interpolation='none')\n",
    "        plt.axis('off') \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read usps dataset\n",
    "usps = fetch_mldata('usps')\n",
    "# size of the sample\n",
    "n = 500\n",
    "# find size amount of samples of number digit\n",
    "digit = 5\n",
    "idx = np.random.choice(usps.data.shape[0],size=n, replace=False)\n",
    "#idx = np.random.choice(np.where((usps.target-1) == digit)[0], size=n, replace=False)\n",
    "\n",
    "# declare training data\n",
    "Xtrain = usps.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data = Xtrain\n",
    "\n",
    "l = len(Data)\n",
    "c = 0.5\n",
    "components = 200\n",
    "\n",
    "# build K\n",
    "K = createK(Data, gaussianKernel, c)\n",
    "\n",
    "# center K\n",
    "K = centerK(K)\n",
    "\n",
    "# find eigen vectors\n",
    "lLambda, alpha = np.linalg.eigh(K) # (3)\n",
    "lambdas = lLambda/l # /l with the notation from the paper (but not murphys) \n",
    "# drop negative and 0 egienvalues and their vectors\n",
    "for i,l in enumerate(lambdas):\n",
    "\tif l > 10**(-8):\n",
    "\t\tlambdas = lambdas[i:]\n",
    "\t\talpha = alpha[i:]\n",
    "\t\tbreak\n",
    "\n",
    "# use only the 4 larges eigen values with corresponding vectors\n",
    "lambdas=lambdas[-components:]\n",
    "alpha=alpha[-components:]\n",
    "\n",
    "# normalize alpha\n",
    "alpha = normAlpha(alpha, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-6129f188edaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalcZ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgaussianKernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-123-ceff817dee1f>\u001b[0m in \u001b[0;36mcalcZ\u001b[1;34m(alpha, data, x, kernelFunction, c, z0)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                         \u001b[1;31m#gammaI = calcGammaI(alpha, i, data, x, kernelFunction, c) * kernelFunction(z,xi,c)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                         \u001b[0mgammaI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcGammaIOpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mkernelFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                         \u001b[0mnumerator\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgammaI\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                         \u001b[0mdenom\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgammaI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-123-ceff817dee1f>\u001b[0m in \u001b[0;36mcalcGammaIOpt\u001b[1;34m(alpha, i, beta)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0malphaI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphaKI\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphaI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mgammaI\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malphaKI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgammaI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "Z = calcZ(alpha, Xtrain, Xtrain[1],gaussianKernel,c,Xtrain[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
